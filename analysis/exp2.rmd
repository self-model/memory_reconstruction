---
title             : "The title"
shorttitle        : "Title"

author: 
  - name          : "First Author"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "Postal address"
    email         : "my@email.com"
    role: # Contributorship roles (e.g., CRediT, https://credit.niso.org/)
      - "Conceptualization"
      - "Writing - Original Draft Preparation"
      - "Writing - Review & Editing"
  - name          : "Ernst-August Doelle"
    affiliation   : "1,2"
    role:
      - "Writing - Review & Editing"
      - "Supervision"

affiliation:
  - id            : "1"
    institution   : "Wilhelm-Wundt-University"
  - id            : "2"
    institution   : "Konstanz Business School"

authornote: |
  Add complete departmental affiliations for each author here. Each new line herein must be indented, like this line.

  Enter author note here.

abstract: |
  One or two sentences providing a **basic introduction** to the field,  comprehensible to a scientist in any discipline.
  Two to three sentences of **more detailed background**, comprehensible  to scientists in related disciplines.
  One sentence clearly stating the **general problem** being addressed by  this particular study.
  One sentence summarizing the main result (with the words "**here we show**" or their equivalent).
  Two or three sentences explaining what the **main result** reveals in direct comparison to what was thought to be the case previously, or how the  main result adds to previous knowledge.
  One or two sentences to put the results into a more **general context**.
  Two or three sentences to provide a **broader perspective**, readily comprehensible to a scientist in any discipline.
  
  <!-- https://tinyurl.com/ybremelq -->
  
keywords          : "keywords"
wordcount         : "X"

bibliography      : "r-references.bib"

floatsintext      : no
linenumbers       : yes
draft             : no
mask              : no

figurelist        : no
tablelist         : no
footnotelist      : no

classoption       : "man"
output            : papaja::apa6_word
---

```{r setup, include = FALSE}
library("papaja")
r_refs("r-references.bib")

library('groundhog')
groundhog.library(
  c(
    'papaja',
    'tidyverse'
  ), "2025-06-01"
)

r_refs("r-references.bib")

knitr::opts_chunk$set(warning=F,echo=F,message=F,cache=T)
```

```{r analysis-preferences}
# Seed for random number generation
set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)
```



# Methods
We report how we determined our sample size, all data exclusions (if any), all manipulations, and all measures in the study. <!-- 21-word solution (Simmons, Nelson & Simonsohn, 2012; retrieved from http://ssrn.com/abstract=2160588) -->

## Participants

## Material

## Procedure

## Preregistered data analysis 
We used `r cite_r("r-references.bib")` for all our analyses.
```{r loadformat, include = FALSE, cache=F}
library(tidyverse)
library(stringr)
library(effsize)



rm(list = ls())

file_list <- '.../data/Experiment2/experimen2_data.txt'

raw_df <- map_dfr(file_list, function(file) {

  lines <- readLines(file)
  starts <- which(grepl('^"?\\s*success', lines))
  starts <- c(starts, length(lines) + 1)
  chunks <- map2(starts[-length(starts)], starts[-1] - 1, ~ lines[.x:.y])
  map_dfr(chunks, ~ read_csv(
      paste(.x, collapse = "\n"),
      show_col_types = FALSE,
      col_types = cols(.default = "c") 
    ))  %>%
  # map_dfr(chunks, ~ read_csv(
  #   paste(.x, collapse = "\n"),
  #   show_col_types = FALSE,
  #   col_types = cols(.default = "c")   
    mutate(
      subj_id = PROLIFIC_PID,
      is_catch_trial = as.logical(is_catch_trial),
      is_show_trial = as.logical(is_show_trial),
      response = as.numeric(response),
      chose_gems = as.logical(chose_gems),
      chose_onlystones = as.logical(chose_onlystones),
      chose_other = as.logical(chose_other),
      left_number = as.numeric(left_number),
      middle_number = as.numeric(middle_number),
      right_number = as.numeric(right_number),
      cumulative_score = as.numeric(cumulative_score),
      is_consistent = as.logical(is_consistent),
      trial_num = as.numeric(trial_num),
      rt = as.numeric(rt),
      confidence_rt = as.numeric(confidence_rt),
      comprehension_failures_part1 = as.numeric(comprehension_failures_part1),
      comprehension_failures_part2_1 = as.numeric(comprehension_failures_part2_1),
      comprehension_failures_part2_2 = as.numeric(comprehension_failures_part2_2),
      comprehension_failures_part2_3 = as.numeric(comprehension_failures_part2_3),
      comprehension_failures_part2_4 = as.numeric(comprehension_failures_part2_4),
      confidence = as.numeric(confidence),
      rule_check = as.character(rule_check),
      worker_comments = as.character(worker_comments),
      number_correct_part1 = as.numeric(number_correct_part1_slider),
      number_correct_part2 = as.numeric(number_correct_part2_slider)
    )
})

comments_sparse_df <- raw_df %>%
  dplyr::select(subj_id, rule_check, worker_comments, number_correct_part1, number_correct_part2) %>%
  dplyr::filter(!is.na(worker_comments) | !is.na(rule_check) | !is.na(number_correct_part1) | !is.na(number_correct_part2))

comments_clean_df <- comments_sparse_df %>%
  group_by(subj_id) %>%
  summarise(
    # For each column, find the first non-NA value for that subject
    rule_check = first(na.omit(rule_check)),
    worker_comments = first(na.omit(worker_comments)),
    number_correct_part1 = first(na.omit(number_correct_part1)),
    number_correct_part2 = first(na.omit(number_correct_part2)),
    .groups = 'drop' 
  )

print(head(comments_clean_df))

write.csv(comments_clean_df, 'comments_exp2_clean.csv', row.names = FALSE)
  
  


# Process data for Phase 1
phase_1_df <- raw_df %>%
  filter(phase == 'part1') %>%
  dplyr::select(
    subj_id,
    trial_num,
    left_word,
    left_number,
    middle_word, 
    middle_number,
    right_word, 
    right_number, 
    chose_gems,
    chose_onlystones,
    chose_other,
    response_position,
    correct_choice_position,
    response_position,
    is_catch_trial, 
    is_show_trial,
    stoneposition,
    emeraldposition,
    rt,
    comprehension_failures_part1,
    number_correct_part1) %>%
  group_by(subj_id) %>%
  arrange(trial_num) 
  




write.csv(raw_df, 'raw_df.csv')
phase_2_df <- raw_df %>%
  filter(phase == 'part2') %>%
  dplyr::select(
    subj_id, 
    trial_num,
    response_position,
    is_consistent,
    correct_choice_position,
    confidence,
    chose_gems,
    chose_onlystones,
    chose_other,
    rt,
    confidence_rt,
    is_catch_trial,
    is_show_trial,
    stoneposition,
    emeraldposition,
    left_word,
    left_number,
    middle_word, 
    middle_number,
    right_word, 
    right_number, 
    comprehension_failures_part2_1,
    comprehension_failures_part2_2,
    comprehension_failures_part2_3,
    comprehension_failures_part2_4,
    number_correct_part2
  ) %>%
  group_by(subj_id) %>%
  arrange(trial_num)  %>%
  filter(!is.na(is_consistent))



#excluding participants

total_participants_before <- length(unique(phase_1_df$subj_id))
cat("Total number of participants before exclusion:", total_participants_before)

exclude_catch <- phase_1_df %>%
  group_by(subj_id) %>%
  summarise(
    n_failed_catch = sum(!chose_gems[is_catch_trial == TRUE], na.rm = TRUE),)%>%
  filter(n_failed_catch >= 2) %>%
  pull(subj_id)

exclude_part1_rt <- phase_1_df %>%
  group_by(subj_id) %>%
  summarise(
  first_quartile_rt = quantile(rt, probs = 0.25, na.rm = TRUE))%>%
  filter(first_quartile_rt < 100 ) %>%
  pull(subj_id)

exclude_part2_rt <- phase_2_df %>%
  group_by(subj_id) %>%
  summarise(
    first_quartile_rt = quantile(rt, probs = 0.25, na.rm = TRUE)) %>%
  filter( first_quartile_rt < 100 ) %>%
  pull(subj_id)

exclude_part2_confidence_rt <- phase_2_df %>%
  group_by(subj_id) %>%
  summarise(
    first_quantile_rt = quantile(confidence_rt, probs = 0.25, na.rm = TRUE)
  ) %>%
  filter(first_quantile_rt < 100) %>%
  pull(subj_id)
  

exclude_comprehension <- raw_df %>%
  filter(comprehension_failures_part1 >= 2 | comprehension_failures_part2_1 >= 2 |  comprehension_failures_part2_2 >= 2| comprehension_failures_part2_3 >= 2| comprehension_failures_part2_4 >= 2) %>%
  distinct(subj_id) %>%
  pull(subj_id)


participants_to_exclude <- unique(c(exclude_catch,
                                    exclude_part1_rt, 
                                    exclude_part2_rt, 
                                    exclude_part2_confidence_rt,
                                    exclude_comprehension))


cat("Number of participants to exclude:", length(participants_to_exclude), "\n")
if (length(participants_to_exclude) > 0) {
  cat("Excluding participants:", paste(participants_to_exclude, collapse=", "), "\n")
}



phase_1_df <- phase_1_df %>%
  filter(!(subj_id %in% participants_to_exclude))

phase_2_df <- phase_2_df %>%
  filter(!(subj_id %in% participants_to_exclude))

# Print total number of participants after exclusion
total_participants_after <- length(unique(phase_1_df$subj_id))
cat("Total number of participants after exclusion:", total_participants_after, "\n")


two_parts_df <- phase_1_df %>%
  inner_join(
    phase_2_df,
    by = c("subj_id", "trial_num"),
    suffix = c("_part1", "_part2")
  )

# rank participants based on score:
top_ids <- raw_df %>%
  dplyr::select(
    subj_id, 
    cumulative_score
) %>%
  filter(!subj_id %in% participants_to_exclude) %>%
  group_by(subj_id) %>%
  summarise(max_cumulative_score = max(cumulative_score, na.rm = TRUE)) %>%
  arrange(desc(max_cumulative_score)) %>%
  slice_head(n = 30) %>% # 20*0.3 = 6
  pull(subj_id)

# bonus participants
print(top_ids)




```

```{r explicit rule discoverers, include = FALSE, cache=F}
### RULE DISCOVERY 

rule_list <- c(
  "546e8bc6fdf99b2bc7ebd029",
  "56d56e550b5634000bdc5703",
  "572bcdbb34b25a0010ddd977",
  "59dd90f6e75b450001a68dac",
  "5ca6717bb54fe60001e22441",
  "5cafc17ace1fa80017a20d6b",
  "5ecf5a78ba30501d2ca5e34b",
  "5ee0edcb962eba464f486b40",
  "5f035c7ce9d86254e87992e4",
  "5f08e3eda7b89d16266b0cdf",
  "6151556ef73ba765c7ff55f6",
  "629f6b8c65fcae219e245284",
  "62fccb9647eb07d62e9b6baa",
  "63af557b3d4f219c3226b7d6",
  "63f77a5dde1ea03305e119e0",
  "63f7ac13d942e94c18c92d4b",
  "64a9858be9b52e570ffb3c1e",
  "661149a91b7fad3a3d2caf0c",
  "6658e2cb395c02efada6a7a1",
  "66661b1242b581f199e49f4c",
  "6693a6ffc58de3bb9c5341de",
  "669eb709554e753adddffe01",
  "66cbc2627559d53c0e3e4ac4",
  "6730f2e20f5915ff4ad2c07d",
  "673e2923ed2dd1f79b63d19d",
  "6762d29bf8f9712a46c73b62",
  "67803b5508f3d995ef13696b",
  "67e069199f5b036960b0cc5f",
  "681b781064a5701a5ceee3bc"
)

two_parts_df <- two_parts_df %>%
  mutate(mentioned_rule = subj_id %in% rule_list)

phase_1_df <- phase_1_df %>%
  mutate(mentioned_rule = subj_id %in% rule_list)

phase_2_df <- phase_2_df %>%
  mutate(mentioned_rule = subj_id %in% rule_list)

```

### phase 1 accuracy

```{r phase_1_and_2_accuracy,  cache=F, fig.width=8}
# --- Define new bins for 50 trials ---
# Bins are now 1-5, 6-10, 11-15, 16-20, 21-25, 26-30, 31-35, 36-40, 41-45, 46-50
bin_labels <- c("1–5", "6–10", "11–15", "16–20", "21–25", 
                "26–30", "31–35", "36–40", "41–45", "46–50")

# Breaks are set at 0.5, 5.5, 10.5, etc. to correctly group the integer trial numbers
breaks <- c(0.5, 5.5, 10.5, 15.5, 20.5, 25.5, 30.5, 35.5, 40.5, 45.5, 50.5)

# This sequence creates vertical lines between the bins (at 1.5, 2.5, etc.)
vline_x <- seq(1.5, length(bin_labels) - 0.5, by = 1)

df_binned <- raw_df %>%
  filter(!is_catch_trial, phase %in% c("part1", "part2")) %>%
  mutate(
    mentioned_rule = subj_id %in% rule_list,
    bin = cut(trial_num, breaks = breaks, labels = bin_labels,
              include.lowest = TRUE, right = TRUE),
    bin = factor(bin, levels = bin_labels)
  )

# --- Summarise by subj, phase, bin, and mentioned_rule ---
by_subj_bias <- df_binned %>%
  group_by(subj_id, phase, bin, mentioned_rule) %>%
  summarise(bias = mean(chose_onlystones, na.rm = TRUE), .groups = "drop")

# --- Subgroup summary (mentioned vs not) ---
group_summary_sub <- by_subj_bias %>%
  group_by(phase, bin, mentioned_rule) %>%
  summarise(
    m  = mean(bias, na.rm = TRUE),
    se = sd(bias,  na.rm = TRUE) / sqrt(n()),
    .groups = "drop"
  )

# --- Overall summary (all subjects, regardless of mentioned_rule) ---
group_summary_all <- by_subj_bias %>%
  group_by(phase, bin) %>%
  summarise(
    m  = mean(bias, na.rm = TRUE),
    se = sd(bias,  na.rm = TRUE) / sqrt(n()),
    .groups = "drop"
  )

# --- Plot both: solid for overall, dotted for subgroups ---
ggplot() +
  # vertical and horizontal lines
  geom_vline(xintercept = vline_x, linetype = "dashed", linewidth = 0.3, color = "grey") +
  geom_hline(yintercept = 1/3, linewidth = 0.3) +
  
  # solid line for overall (collapsed) mean
  geom_line(data = group_summary_all,
            aes(x = bin, y = m, group = phase, color = phase),
            linewidth = 1) +
  geom_point(data = group_summary_all,
             aes(x = bin, y = m, color = phase),
             size = 2) +
  
  # dotted lines for subgroups (mentioned vs not)
  geom_line(data = group_summary_sub,
            aes(x = bin, y = m, group = interaction(phase, mentioned_rule),
                color = phase, linetype = mentioned_rule),
            linewidth = 0.7) +
  geom_point(data = group_summary_sub,
             aes(x = bin, y = m, color = phase, shape = mentioned_rule),
             size = 2) +
  
  # error bars for subgroups
  geom_errorbar(data = group_summary_sub,
                aes(x = bin, y = m, ymin = m - se, ymax = m + se,
                    color = phase),
                width = 0.2) +
  
  scale_linetype_manual(
    name = "Mentioned rule",
    values = c("TRUE" = "dotted", "FALSE" = "dotdash"),
    labels = c("TRUE" = "Mentioned", "FALSE" = "Not mentioned")
  ) +
  scale_shape_manual(
    name = "Mentioned rule",
    values = c("TRUE" = 16, "FALSE" = 1),
    labels = c("TRUE" = "Mentioned", "FALSE" = "Not mentioned")
  ) +
  labs(x = "Trial Bin", y = "P(stones only)",
       title = "Binned Bias by Phase (Group Mean ± SE)",
       color = "Phase") +
  theme_minimal()



phase_1_acc <- phase_1_df %>%
  group_by(subj_id) %>%
  filter(!is_catch_trial) %>%
  summarise(acc=mean(chose_gems))

r_phase_1_acc <- phase_1_df %>%
  group_by(subj_id) %>%
  filter(!is_catch_trial, mentioned_rule) %>%
  summarise(acc=mean(chose_gems))

nr_phase_1_acc <- phase_1_df %>%
  group_by(subj_id) %>%
  filter(!is_catch_trial, !mentioned_rule) %>%
  summarise(acc=mean(chose_gems))

phase_1_acc_slopes <- phase_1_df %>%
  group_by(subj_id) %>%
  filter(!is_catch_trial) %>%
  summarise(r=cor(chose_gems,trial_num))

r_phase_1_acc_slopes <- phase_1_df %>%
  group_by(subj_id) %>%
  filter(!is_catch_trial, mentioned_rule) %>%
  summarise(r=cor(chose_gems,trial_num))

nr_phase_1_acc_slopes <- phase_1_df %>%
  group_by(subj_id) %>%
  filter(!is_catch_trial, !mentioned_rule) %>%
  summarise(r=cor(chose_gems,trial_num))

phase_2_acc <- phase_2_df %>%
  group_by(subj_id) %>%
  filter(!is_catch_trial) %>%
  summarise(acc=mean(is_consistent, na.rm =TRUE))

r_phase_2_acc <- phase_2_df %>%
  group_by(subj_id) %>%
  filter(!is_catch_trial, mentioned_rule) %>%
  summarise(acc=mean(is_consistent, na.rm =TRUE))

nr_phase_2_acc <- phase_2_df %>%
  group_by(subj_id) %>%
  filter(!is_catch_trial, !mentioned_rule) %>%
  summarise(acc=mean(is_consistent, na.rm =TRUE))

phase_2_acc_slopes <- phase_2_df %>%
  group_by(subj_id) %>%
  filter(!is_catch_trial) %>%
  summarise(r=cor(is_consistent,trial_num, use = "complete.obs"))

r_phase_2_acc_slopes <- phase_2_df %>%
  group_by(subj_id) %>%
  filter(!is_catch_trial, mentioned_rule) %>%
  summarise(r=cor(is_consistent,trial_num, use = "complete.obs"))

nr_phase_2_acc_slopes <- phase_2_df %>%
  group_by(subj_id) %>%
  filter(!is_catch_trial, !mentioned_rule) %>%
  summarise(r=cor(is_consistent,trial_num, use = "complete.obs"))

```


In part 1, mean proportion correct (in non-catch trials) was `r phase_1_acc %>% pull(acc) %>%mean()%>%printnum()` (median=`r phase_1_acc %>% pull(acc) %>%median()%>%printnum()`) and was significantly higher than chance (1/3; `r apa_print(t.test(phase_1_acc %>% pull(acc),mu=1/3))$statistic`). Participants significantly improved as a function of trial number (a t-test on subject-specific learning slopes against 0: `r apa_print(t.test(phase_1_acc_slopes %>% pull(r)))$statistic`). 

The mean accuracy for participants who mentioned the rule was `r r_phase_1_acc %>% pull(acc) %>%mean()%>%printnum()` (median=`r r_phase_1_acc %>% pull(acc) %>%median()%>%printnum()`) and was significantly higher than chance (1/3; `r apa_print(t.test(r_phase_1_acc %>% pull(acc),mu=1/3))$statistic`). Participants significantly improved as a function of trial number (a t-test on subject-specific learning slopes against 0: `r apa_print(t.test(r_phase_1_acc_slopes %>% pull(r)))$statistic`). 

The mean accuracy for participants who did not mention the rule was r `nr_phase_1_acc %>% pull(acc) %>%mean()%>%printnum()` (median=`r nr_phase_1_acc %>% pull(acc) %>%median()%>%printnum()`) and was not significantly higher than chance (1/3; `r apa_print(t.test(nr_phase_1_acc %>% pull(acc),mu=1/3))$statistic`). Participants did not improve as a function of trial number (a t-test on subject-specific learning slopes against 0: `r apa_print(t.test(nr_phase_1_acc_slopes %>% pull(r)))$statistic`). 



### Hypothesis 1 (RULE LEARNING AVOIDANCE)

```{r phase1avoidance, include = FALSE, cache=F}
phase_1_pstones <- phase_1_df %>%
  group_by(subj_id) %>%
  filter(!is_catch_trial) %>%
  summarise(pstones=mean(chose_onlystones,na.rm = TRUE))

r_phase_1_pstones <- phase_1_df %>%
  group_by(subj_id) %>%
  filter(!is_catch_trial, mentioned_rule) %>%
  summarise(pstones=mean(chose_onlystones,na.rm = TRUE))

nr_phase_1_pstones <- phase_1_df %>%
  group_by(subj_id) %>%
  filter(!is_catch_trial, !mentioned_rule) %>%
  summarise(pstones=mean(chose_onlystones,na.rm = TRUE))


```

In part 1, participants chose the side that always had stones (in non-catch trials)  on `r phase_1_pstones %>% pull(pstones) %>%mean()%>%printnum()` (median=`r phase_1_pstones %>% pull(pstones) %>%median()%>%printnum()`) of all trials, significantly below chance (1/3; `r apa_print(t.test(phase_1_pstones %>% pull(pstones),mu=1/3))$statistic`).

Participants who mentioned the rule chose the side that always had stones on `r r_phase_1_pstones %>% pull(pstones) %>%mean()%>%printnum()` (median=`r r_phase_1_pstones %>% pull(pstones) %>%median()%>%printnum()`) of all trials, significantly below chance (1/3; `r apa_print(t.test(r_phase_1_pstones %>% pull(pstones),mu=1/3))$statistic`). This is in contrast to participants who did not mention the rule who chose the side that always had stones on `r nr_phase_1_pstones %>% pull(pstones) %>%mean()%>%printnum()` (median=`r nr_phase_1_pstones %>% pull(pstones) %>%median()%>%printnum()`) of all trials, significantly below chance (1/3; `r apa_print(t.test(nr_phase_1_pstones %>% pull(pstones),mu=1/3))$statistic`). The difference in means between the two groups are significant (`r apa_print(t.test(r_phase_1_pstones %>% pull(pstones),nr_phase_1_pstones %>% pull(pstones)))$statistic`)

### Hypothesis 2 (RULE LEARNING: SLOPES)

```{r phase1slopes, include = FALSE, cache=F}
library(broom)
pstones_slopes <- two_parts_df %>%
  group_by(subj_id) %>%
  filter(!is_catch_trial_part1) %>% 
  do(tidy(glm(
    chose_onlystones_part1 ~ trial_num, 
    family = binomial, 
    data = .
  ))) %>%
  filter(term == "trial_num") %>%
  select(subj_id, slope = estimate)

r_pstones_slopes <- two_parts_df %>%
  group_by(subj_id) %>%
  filter(!is_catch_trial_part1, mentioned_rule) %>% 
  do(tidy(glm(
    chose_onlystones_part1 ~ trial_num, 
    family = binomial, 
    data = .
  ))) %>%
  filter(term == "trial_num") %>%
  select(subj_id, slope = estimate)

nr_pstones_slopes <- two_parts_df %>%
  group_by(subj_id) %>%
  filter(!is_catch_trial_part1, !mentioned_rule) %>% 
  do(tidy(glm(
    chose_onlystones_part1 ~ trial_num, 
    family = binomial, 
    data = .
  ))) %>%
  filter(term == "trial_num") %>%
  select(subj_id, slope = estimate)


```

Participants improved as a function of trial number (a t-test on subject-specific learning slopes from a logistic regression against 0: `r apa_print(t.test(pstones_slopes %>% pull(slope)))$statistic`).This was true for participants who explicitly learnt the rule (`r apa_print(t.test(r_pstones_slopes %>% pull(slope)))$statistic`) and true for participants who did not learn the rule (`r apa_print(t.test(nr_pstones_slopes %>% pull(slope)))$statistic`). 

### Hypothesis 3 (RECONSTRUCTION ACCURACY)

In part 2, mean proportion correct (in non-catch trials) was `r phase_2_acc %>% pull(acc) %>%mean()%>%printnum()` (median=`r phase_2_acc %>% pull(acc) %>%median()%>%printnum()`) and significantly higher than chance (1/3; `r apa_print(t.test(phase_2_acc %>% pull(acc),mu=1/3))$statistic`). 

Mean accuracy for participants who mentioned rule was `r r_phase_2_acc %>% pull(acc) %>%mean()%>%printnum()` (median=`r r_phase_2_acc %>% pull(acc) %>%median()%>%printnum()`) and significantly higher than chance (1/3; `r apa_print(t.test(r_phase_2_acc %>% pull(acc),mu=1/3))$statistic`). 

Mean accuracy for participants who did not mention the rule was `r nr_phase_2_acc %>% pull(acc) %>%mean()%>%printnum()` (median=`r nr_phase_2_acc %>% pull(acc) %>%median()%>%printnum()`) and significantly higher than chance (1/3; `r apa_print(t.test(nr_phase_2_acc %>% pull(acc),mu=1/3))$statistic`). 

The difference in mean between the two groups are not significant (`r apa_print(t.test(r_phase_2_acc %>% pull(acc),nr_phase_2_acc %>% pull(acc)))$statistic`). 

### Hytpoehsis 4 (RECONSTRUCTION ACCURACY BY GUESS ACCURACY): 

```{r hypothesis_4, include = FALSE, cache=F}

part1_choices <- phase_1_df %>%
  select(subj_id, trial_num, part1_chose_gems = chose_gems)

paired_data <- phase_2_df %>%
  left_join(part1_choices, by = c("subj_id", "trial_num")) %>%
  filter(!is_catch_trial, !is.na(part1_chose_gems)) %>%
  group_by(subj_id, part1_chose_gems) %>%
  summarise(mean_accuracy = mean(is_consistent, na.rm = TRUE), .groups = 'drop') %>%
  pivot_wider(names_from = part1_chose_gems, values_from = mean_accuracy)

r_paired_data <- phase_2_df %>%
  left_join(part1_choices, by = c("subj_id", "trial_num")) %>%
  filter(!is_catch_trial, !is.na(part1_chose_gems), mentioned_rule) %>%
  group_by(subj_id, part1_chose_gems) %>%
  summarise(mean_accuracy = mean(is_consistent, na.rm = TRUE), .groups = 'drop') %>%
  pivot_wider(names_from = part1_chose_gems, values_from = mean_accuracy)

nr_paired_data <- phase_2_df %>%
  left_join(part1_choices, by = c("subj_id", "trial_num")) %>%
  filter(!is_catch_trial, !is.na(part1_chose_gems), !mentioned_rule) %>%
  group_by(subj_id, part1_chose_gems) %>%
  summarise(mean_accuracy = mean(is_consistent, na.rm = TRUE), .groups = 'drop') %>%
  pivot_wider(names_from = part1_chose_gems, values_from = mean_accuracy)

hyp4_test <- t.test(x = paired_data$`TRUE`, 
                    y = paired_data$`FALSE`, 
                    paired = TRUE,
                    alternative = "two.sided")


hyp4_d <- cohen.d(paired_data$`TRUE`, 
                  paired_data$`FALSE`, 
                  paired = TRUE)

r_hyp4_test <- t.test(x = r_paired_data$`TRUE`, 
                    y = r_paired_data$`FALSE`, 
                    paired = TRUE,
                    alternative = "two.sided")


r_hyp4_d <- cohen.d(r_paired_data$`TRUE`, 
                  r_paired_data$`FALSE`, 
                  paired = TRUE)

nr_hyp4_test <- t.test(x = nr_paired_data$`TRUE`, 
                    y = nr_paired_data$`FALSE`, 
                    paired = TRUE,
                    alternative = "two.sided")


nr_hyp4_d <- cohen.d(nr_paired_data$`TRUE`, 
                  nr_paired_data$`FALSE`, 
                  paired = TRUE)

mean_acc_true <- mean(paired_data[["TRUE"]], na.rm = TRUE)
r_mean_acc_true <- mean(r_paired_data[["TRUE"]], na.rm = TRUE)
nr_mean_acc_true <- mean(nr_paired_data[["TRUE"]], na.rm = TRUE)

mean_acc_false <- mean(paired_data[["FALSE"]], na.rm = TRUE)
r_mean_acc_false <- mean(r_paired_data[["FALSE"]], na.rm = TRUE)
nr_mean_acc_false <- mean(nr_paired_data[["FALSE"]], na.rm = TRUE)
```

Participants' ability to reconstruct their past decisions was significantly **higher** when they were correct in part 1 (mean accuracy = `r printnum(mean_acc_true)`) compared to incorrect (mean accuracy = `r printnum(mean_acc_false)`; `r apa_print(hyp4_test)$statistic`). 

For participants who mentioned the rule, their ability to reconstruct their past decisions was significantly higher when they were correct in part 1 (mean accuracy = `r printnum(r_mean_acc_true)`) compared to incorrect (mean accuracy = `r printnum(r_mean_acc_false)`; `r apa_print(r_hyp4_test)$statistic`). 

For participants who did not mention the rule, their ability to reconstruct their past decisions was higher when they were correct in part 1 (mean accuracy = `r printnum(nr_mean_acc_true)`) compared to incorrect (mean accuracy = `r printnum(nr_mean_acc_false)`. However, this result was not significant: `r apa_print(nr_hyp4_test)$statistic`). 

```{r accuracy,  cache=F, fig.width=8}



part1_choices <- phase_1_df %>%
  select(subj_id, trial_num, part1_chose_gems = chose_gems)

phase_2_merged_df <- phase_2_df %>%
  left_join(part1_choices, by = c("subj_id", "trial_num"))

data_for_test <- phase_2_merged_df %>%
  filter(!is_catch_trial, !is.na(part1_chose_gems))

long_paired_data_all <- data_for_test %>%
  group_by(subj_id, part1_chose_gems) %>%
  summarise(mean_accuracy = mean(is_consistent, na.rm = TRUE), .groups = "drop") %>%
  mutate(
    phase_1_choice = factor(part1_chose_gems, labels = c("Did Not Choose Gems", "Chose Gems")),
    group = "all"
  )

r_long_paired_data <- data_for_test %>%
  filter(mentioned_rule) %>%
  group_by(subj_id, part1_chose_gems) %>%
  summarise(mean_accuracy = mean(is_consistent, na.rm = TRUE), .groups = "drop") %>%
  mutate(
    phase_1_choice = factor(part1_chose_gems, labels = c("Did Not Choose Gems", "Chose Gems")),
    group = "r_mentioned"
  )

nr_long_paired_data <- data_for_test %>%
  filter(!mentioned_rule) %>%
  group_by(subj_id, part1_chose_gems) %>%
  summarise(mean_accuracy = mean(is_consistent, na.rm = TRUE), .groups = "drop") %>%
  mutate(
    phase_1_choice = factor(part1_chose_gems, labels = c("Did Not Choose Gems", "Chose Gems")),
    group = "nr_not_mentioned"
  )

plot_data_summary_all <- long_paired_data_all %>%
  group_by(group, phase_1_choice) %>%
  summarise(
    grand_mean_accuracy = mean(mean_accuracy, na.rm = TRUE),
    n = n(),
    sem = sd(mean_accuracy, na.rm = TRUE) / sqrt(n),
    .groups = "drop"
  )

r_plot_data_summary <- r_long_paired_data %>%
  group_by(group, phase_1_choice) %>%
  summarise(
    grand_mean_accuracy = mean(mean_accuracy, na.rm = TRUE),
    n = n(),
    sem = sd(mean_accuracy, na.rm = TRUE) / sqrt(n),
    .groups = "drop"
  )

nr_plot_data_summary <- nr_long_paired_data %>%
  group_by(group, phase_1_choice) %>%
  summarise(
    grand_mean_accuracy = mean(mean_accuracy, na.rm = TRUE),
    n = n(),
    sem = sd(mean_accuracy, na.rm = TRUE) / sqrt(n),
    .groups = "drop"
  )

plot_data_summary <- bind_rows(plot_data_summary_all,
                               r_plot_data_summary,
                               nr_plot_data_summary) %>%
  mutate(group = factor(group, levels = c("all", "r_mentioned", "nr_not_mentioned")))

long_subject_all <- long_paired_data_all
long_subject_r   <- r_long_paired_data
long_subject_nr  <- nr_long_paired_data

y_limits <- c(0, 1)

build_group_plot <- function(summary_df, subject_df, plot_title, bar_color) {
  ggplot(summary_df, aes(x = phase_1_choice, y = grand_mean_accuracy)) +
    geom_line(data = subject_df,
              aes(x = phase_1_choice, y = mean_accuracy, group = subj_id),
              color = "gray70", alpha = 0.4, inherit.aes = FALSE) +
    geom_point(data = subject_df,
               aes(x = phase_1_choice, y = mean_accuracy, group = subj_id),
               color = "gray70", alpha = 0.4, inherit.aes = FALSE) +
    # bars
    geom_bar(stat = "identity", width = 0.6, fill = bar_color) +
    # error bars
    geom_errorbar(aes(ymin = grand_mean_accuracy - sem, ymax = grand_mean_accuracy + sem),
                  width = 0.2, color = "black") +
    labs(title = plot_title,
         x = "Choice in Phase 1",
         y = "Mean Phase 2 Accuracy") +
    scale_y_continuous(limits = y_limits, expand = c(0, 0)) +
    theme_minimal() +
    theme(legend.position = "none",
          plot.title = element_text(size = 11, face = "bold"))
}

# --- create each plot ---
plot_all <- build_group_plot(plot_data_summary_all, long_subject_all,
                             "All participants", "#4C72B0")

plot_r <- build_group_plot(r_plot_data_summary, long_subject_r,
                           "Rule mentioned", "#55A868")

plot_nr <- build_group_plot(nr_plot_data_summary, long_subject_nr,
                            "Rule NOT mentioned", "#C44E52")

print(plot_all)
print(plot_r)
print(plot_nr)




```


### Hypothesis 5 (REMEMBERED ACCURACY VERSUS TRUE ACCURACY)

```{r hypothesis_5, include = FALSE, cache=F}

# all participants
accuracy_df <- phase_1_df %>%
  filter(!is_catch_trial) %>%
  group_by(subj_id) %>%
  summarise(actual_accuracy = mean(chose_gems), .groups = "drop") %>%
  left_join(
    phase_2_df %>%
      filter(!is_catch_trial) %>%
      group_by(subj_id) %>%
      summarise(remembered_accuracy = mean(chose_gems), .groups = "drop"),
    by = "subj_id"
  )

# paired t-test


# r_mentioned
r_accuracy_df <- phase_1_df %>%
  filter(!is_catch_trial, mentioned_rule) %>%
  group_by(subj_id) %>%
  summarise(actual_accuracy = mean(chose_gems), .groups = "drop") %>%
  left_join(
    phase_2_df %>%
      filter(!is_catch_trial, mentioned_rule) %>%
      group_by(subj_id) %>%
      summarise(remembered_accuracy = mean(chose_gems), .groups = "drop"),
    by = "subj_id"
  )



# nr_not_mentioned
nr_accuracy_df <- phase_1_df %>%
  filter(!is_catch_trial, !mentioned_rule) %>%
  group_by(subj_id) %>%
  summarise(actual_accuracy = mean(chose_gems), .groups = "drop") %>%
  left_join(
    phase_2_df %>%
      filter(!is_catch_trial, !mentioned_rule) %>%
      group_by(subj_id) %>%
      summarise(remembered_accuracy = mean(chose_gems), .groups = "drop"),
    by = "subj_id"
  )




```

Participants remembered their guesses as aligned with the location of the gems on `r accuracy_df$remembered_accuracy%>%mean()%>%printnum()`, a frequency significantly higher than their actual accuracy in part 1, which was `r accuracy_df$actual_accuracy%>%mean()%>%printnum()` (`r apa_print(t.test(accuracy_df$remembered_accuracy, accuracy_df$actual_accuracy, paired = TRUE))$statistic`).

Participants who mentioned the rule remembered their guesses as aligned with the location of the gems on `r r_accuracy_df$remembered_accuracy%>%mean()%>%printnum()`, a frequency not significantly higher than their actual accuracy in part 1, which was `r r_accuracy_df$actual_accuracy%>%mean()%>%printnum()` (`r apa_print(t.test(r_accuracy_df$remembered_accuracy, r_accuracy_df$actual_accuracy, paired = TRUE))$statistic`).

Participants remembered their guesses as aligned with the location of the gems on `r nr_accuracy_df$remembered_accuracy%>%mean()%>%printnum()`, a frequency not significantly higher than their actual accuracy in part 1, which was `r nr_accuracy_df$actual_accuracy%>%mean()%>%printnum()` (`r apa_print(t.test(nr_accuracy_df$remembered_accuracy, nr_accuracy_df$actual_accuracy, paired = TRUE))$statistic`).


### Hypothesis 6 (POSITION BIAS IN RECONSTRUCTION ERRORS

We will test the null hypothesis that participants’remembered decisions are not biased for or against the stones-only location. For this, we will focus on trials in which the original decision revealed gems, but they made an error in reconstruction. We will compare the probability of choosing the stones-only position against 50%. Since different participants will have different number of trials for this analysis, this will be tested using a mixed-effects logistic regression (chose_stones_only∼1+(1|subj_id), run with lme4’s glmer, assuming a binomial variable and using a bobyqa optimizer).

```{r hypothesis_6, include = TRUE, cache=F}

part1_choices <- phase_1_df %>%
  select(subj_id, trial_num, part1_chose_gems = chose_gems)

phase_2_merged_df <- phase_2_df %>%
  left_join(part1_choices, by = c("subj_id", "trial_num"))

is_not_consistent_chosegems_part1 <- phase_2_merged_df %>%
  filter(!is_catch_trial, !is.na(part1_chose_gems), !is_consistent) 

r_is_not_consistent_chosegems_part1 <- phase_2_merged_df %>%
  filter(!is_catch_trial, !is.na(part1_chose_gems), !is_consistent, mentioned_rule)

nr_is_not_consistent_chosegems_part1 <- phase_2_merged_df %>%
  filter(!is_catch_trial, !is.na(part1_chose_gems), !is_consistent, !mentioned_rule) 


library(lme4)


h6_model <- glmer(chose_onlystones ~ 1 + (1 | subj_id),
                  data = is_not_consistent_chosegems_part1,
                  family = binomial,
                  control = glmerControl(optimizer = "bobyqa"))

r_h6_model <- glmer(chose_onlystones ~ 1 + (1 | subj_id),
                  data = r_is_not_consistent_chosegems_part1,
                  family = binomial,
                  control = glmerControl(optimizer = "bobyqa"))

nr_h6_model <- glmer(chose_onlystones ~ 1 + (1 | subj_id),
                  data = nr_is_not_consistent_chosegems_part1,
                  family = binomial,
                  control = glmerControl(optimizer = "bobyqa"))


```

In Part 2 trials in which the original decision revealed gems but participants made an error in reconstruction, the estimated probability of selecting the stones-only position was `r printnum(round(unname(1 / (1 + exp(-fixef(h6_model)))), 2))` (p `r printp(summary(h6_model)$coefficients[,"Pr(>|z|)"][1])`).

For participants who mentioned the rule the estimated probability of selecting the stones-only position was `r printnum(round(unname(1 / (1 + exp(-fixef(r_h6_model)))), 2))` (p `r printp(summary(r_h6_model)$coefficients[,"Pr(>|z|)"][1])`).

For participants who did not mention the rule, the estimated probability of selecting the stones-only position was `r printnum(round(unname(1 / (1 + exp(-fixef(nr_h6_model)))), 2))` (p `r printp(summary(nr_h6_model)$coefficients[,"Pr(>|z|)"][1])`).

```{r probability,  cache=F, fig.width=8}


# 1. Create the trial bins and summarize the data
h6_viz_data <- is_not_consistent_chosegems_part1 %>%
  
  # First, create the 5 trial bins
  mutate(
    trial_bin = cut(
      trial_num,
      breaks = c(0, 10, 20, 30, 40, 50),
      labels = c("1-10", "11-20", "21-30", "31-40", "41-50")
    )
  ) %>%
  
  # Now, group by the bins AND by the rule-mentioning group
  group_by(trial_bin, mentioned_rule) %>%
  
  # Calculate the probability, count (for CI), and standard error
  summarise(
    n = n(),
    prob_stones = mean(chose_onlystones, na.rm = TRUE),
    se = sqrt(prob_stones * (1 - prob_stones) / n) # Std. Error of a proportion
  ) %>%
  
  # Calculate 95% Confidence Intervals
  mutate(
    ci_lower = prob_stones - 1.96 * se,
    ci_upper = prob_stones + 1.96 * se
  ) %>%
  
  # Ungroup and also recode 'mentioned_rule' for a clearer plot legend
  ungroup() %>%
  mutate(
    Group = ifelse(mentioned_rule, "Rule mentioned", "Rule not mentioned")
  )

# 2. Create the plot
ggplot(h6_viz_data, aes(x = trial_bin, y = prob_stones, group = Group, color = Group)) +
  
  # Add the 50% null hypothesis line
  geom_hline(
    yintercept = 0.5,
    linetype = "dashed",
    color = "red",
    linewidth = 1
  ) +
  
  # Add error bars
  geom_errorbar(
    aes(ymin = ci_lower, ymax = ci_upper),
    width = 0.2,
    alpha = 0.7
  ) +
  
  # Add lines and points
  geom_line(linewidth = 1.2, alpha = 0.7) +
  geom_point(size = 3) +
  
  # Clean up labels and appearance
  scale_y_continuous(
    labels = scales::percent_format(),
    limits = c(0, 1) # Set y-axis from 0% to 100%
  ) +
  labs(
    title = "Hypothesis 6: Bias in Reconstruction Errors",
    subtitle = "Trials where original choice revealed gems, but reconstruction was an error.",
    x = "Trial Bin",
    y = "Probability of Choosing Stones-Only Location",
    color = "Participant Group" # Legend title
  ) +
  theme_minimal() +
  theme(legend.position = "bottom")
```

 
### Hypothesis 7 (CONFIDENCE: CORRECR VERSUS INCORRECT)

```{r hypothesis_7, include = FALSE, cache=F}

conf_mean_correct <- phase_2_df %>%
  group_by(subj_id) %>%
  filter(!is_catch_trial, is_consistent) %>%
  summarise(mean_conf = mean(confidence, na.rm = TRUE),
            median_conf = median(confidence, na.rm=TRUE))

r_conf_mean_correct <- phase_2_df %>%
  group_by(subj_id) %>%
  filter(!is_catch_trial, is_consistent, mentioned_rule) %>%
  summarise(mean_conf = mean(confidence, na.rm = TRUE),
            median_conf = median(confidence, na.rm=TRUE))

nr_conf_mean_correct <- phase_2_df %>%
  group_by(subj_id) %>%
  filter(!is_catch_trial, is_consistent, !mentioned_rule) %>%
  summarise(mean_conf = mean(confidence, na.rm = TRUE),
            median_conf = median(confidence, na.rm=TRUE))


conf_mean_incorrect <- phase_2_df %>%
  group_by(subj_id) %>%
  filter(!is_catch_trial, !is_consistent) %>%
  summarise(mean_conf = mean(confidence, na.rm=TRUE),
            median_conf = median(confidence, na.rm=TRUE))

r_conf_mean_incorrect <- phase_2_df %>%
  group_by(subj_id) %>%
  filter(!is_catch_trial, !is_consistent, mentioned_rule) %>%
  summarise(mean_conf = mean(confidence, na.rm=TRUE),
            median_conf = median(confidence, na.rm=TRUE))

nr_conf_mean_incorrect <- phase_2_df %>%
  group_by(subj_id) %>%
  filter(!is_catch_trial, !is_consistent,!mentioned_rule) %>%
  summarise(mean_conf = mean(confidence, na.rm=TRUE),
            median_conf = median(confidence, na.rm=TRUE))


```

In part 2, mean confidence for correct decisions was `r conf_mean_correct$mean_conf%>%mean()%>%printnum()` (median=`r conf_mean_correct$median_conf%>%median()%>%printnum()`). The mean confidence for incorrect decisions was `r conf_mean_incorrect$mean_conf%>%mean()%>%printnum()` (median=`r conf_mean_incorrect$median_conf%>%median()%>%printnum()`). The difference in confidence was significant `r apa_print(t.test(x=conf_mean_correct$mean_conf, y=conf_mean_incorrect$mean_conf, alternative="two.sided",paired=TRUE))$statistic`

For participants who mentioned the rule, mean confidence for correct decisions was `r r_conf_mean_correct$mean_conf%>%mean()%>%printnum()` (median=`r r_conf_mean_correct$median_conf%>%median()%>%printnum()`). The mean confidence for incorrect decisions was `r r_conf_mean_incorrect$mean_conf%>%mean()%>%printnum()` (median=`r r_conf_mean_incorrect$median_conf%>%median()%>%printnum()`). The difference in confidence was significant `r apa_print(t.test(x=r_conf_mean_correct$mean_conf, y=r_conf_mean_incorrect$mean_conf, alternative="two.sided",paired=TRUE))$statistic`

For participants who did not mention the rule, mean confidence for correct decisions was `r nr_conf_mean_correct$mean_conf%>%mean()%>%printnum()` (median=`r nr_conf_mean_correct$median_conf%>%median()%>%printnum()`). The mean confidence for incorrect decisions was `r nr_conf_mean_incorrect$mean_conf%>%mean()%>%printnum()` (median=`r nr_conf_mean_incorrect$median_conf%>%median()%>%printnum()`). The difference in confidence was significant `r apa_print(t.test(x=nr_conf_mean_correct$mean_conf, y=nr_conf_mean_incorrect$mean_conf, alternative="two.sided",paired=TRUE))$statistic`


### Hypothesis 8 (CONFIDENCE: GEMS VERSUS STONES)

```{r hypothesis_8, include = FALSE, cache=F}
gem_conf <- phase_2_df %>%
  group_by(subj_id) %>%
  filter(!is_catch_trial, !is_consistent, chose_gems) %>%
  summarise(mean_conf=mean(confidence),
            median = median(confidence))

r_gem_conf <- phase_2_df %>%
  group_by(subj_id) %>%
  filter(!is_catch_trial, !is_consistent, chose_gems, mentioned_rule) %>%
  summarise(mean_conf=mean(confidence),
            median = median(confidence))

nr_gem_conf <- phase_2_df %>%
  group_by(subj_id) %>%
  filter(!is_catch_trial, !is_consistent, chose_gems, !mentioned_rule) %>%
  summarise(mean_conf=mean(confidence),
            median = median(confidence))

stone_conf <- phase_2_df %>% 
  group_by(subj_id) %>%
  filter(!is_catch_trial, !is_consistent, !chose_gems) %>%
  summarise(mean_conf=mean(confidence),
            median = median(confidence))

r_stone_conf <- phase_2_df %>% 
  group_by(subj_id) %>%
  filter(!is_catch_trial, !is_consistent, !chose_gems, mentioned_rule) %>%
  summarise(mean_conf=mean(confidence),
            median = median(confidence))

nr_stone_conf <- phase_2_df %>% 
  group_by(subj_id) %>%
  filter(!is_catch_trial, !is_consistent, !chose_gems, !mentioned_rule) %>%
  summarise(mean_conf=mean(confidence),
            median = median(confidence))

conf_df <- gem_conf %>%
  rename(mean_conf_gem = mean_conf, median_gem = median) %>%
  inner_join(stone_conf %>% rename(mean_conf_stone = mean_conf, median_stone = median),
             by = "subj_id")

r_conf_df <- r_gem_conf %>%
  rename(mean_conf_gem = mean_conf, median_gem = median) %>%
  inner_join(r_stone_conf %>% rename(mean_conf_stone = mean_conf, median_stone = median),
             by = "subj_id")

nr_conf_df <- nr_gem_conf %>%
  rename(mean_conf_gem = mean_conf, median_gem = median) %>%
  inner_join(nr_stone_conf %>% rename(mean_conf_stone = mean_conf, median_stone = median),
             by = "subj_id")


```

In part 2, mean confidence when touching gems on trials in which participants were correct was `r gem_conf$mean_conf %>%mean()%>%printnum()` (median=`r gem_conf$median%>%median()%>%printnum() `). In trials which they chose stones, it was `r stone_conf$mean_conf %>%mean()%>%printnum()` (median=`r  stone_conf$median%>%median()%>%printnum() `). This difference was significant (`r apa_print(t.test(conf_df$mean_conf_gem, conf_df$mean_conf_stone, paired=TRUE))$statistic`). 

For participants who mentioned the rule, mean confidence when touching gems on trials in which participants were correct was `r r_gem_conf$mean_conf %>%mean()%>%printnum()` (median=`r r_gem_conf$median%>%median()%>%printnum() `). In trials which they chose stones, it was `r r_stone_conf$mean_conf %>%mean()%>%printnum()` (median=`r  r_stone_conf$median%>%median()%>%printnum() `). This difference was significant (`r apa_print(t.test(r_conf_df$mean_conf_gem, r_conf_df$mean_conf_stone, paired=TRUE))$statistic`). 

For participants who did not mention the rule, , mean confidence when touching gems on trials in which participants were correct was `r nr_gem_conf$mean_conf %>%mean()%>%printnum()` (median=`r nr_gem_conf$median%>%median()%>%printnum() `). In trials which they chose stones, it was `r nr_stone_conf$mean_conf %>%mean()%>%printnum()` (median=`r  nr_stone_conf$median%>%median()%>%printnum() `). This difference was significant (`r apa_print(t.test(nr_conf_df$mean_conf_gem, nr_conf_df$mean_conf_stone, paired=TRUE))$statistic`). 

```{r hypothesis8_plot, include = TRUE, cache=F}
library(dplyr)
library(ggplot2)

# helper to compute summary by subgroup
compute_plot_data <- function(df) {
  df %>%
    filter(is_consistent, !is_catch_trial) %>%
    mutate(
      choice_type = case_when(
        chose_gems       ~ "Chose Gems",
        chose_other      ~ "Chose Other",
        chose_onlystones ~ "Chose Only Stones",
        TRUE             ~ NA_character_
      )
    ) %>%
    filter(!is.na(choice_type)) %>%
    group_by(choice_type) %>%
    summarise(
      mean_confidence = mean(confidence, na.rm = TRUE),
      n = n(),
      sem = sd(confidence, na.rm = TRUE) / sqrt(n),
      .groups = "drop"
    ) %>%
    mutate(choice_type = factor(choice_type, 
                                levels = c("Chose Gems", "Chose Other", "Chose Only Stones")))
}

# compute summaries
plot_data_all <- compute_plot_data(phase_2_df)
plot_data_r   <- compute_plot_data(filter(phase_2_df, mentioned_rule))
plot_data_nr  <- compute_plot_data(filter(phase_2_df, !mentioned_rule))

# consistent y-axis across all plots
all_max <- max(
  c(plot_data_all$mean_confidence + plot_data_all$sem,
    plot_data_r$mean_confidence + plot_data_r$sem,
    plot_data_nr$mean_confidence + plot_data_nr$sem),
  na.rm = TRUE
)
y_limits <- c(0, ifelse(is.finite(all_max), all_max * 1.05, 1))

# colors
choice_colors <- c(
  "Chose Gems" = "#4C72B0",
  "Chose Other" = "#55A868",
  "Chose Only Stones" = "#C44E52"
)

# plotting function
build_conf_plot <- function(summary_df, plot_title) {
  ggplot(summary_df, aes(x = choice_type, y = mean_confidence, fill = choice_type)) +
    geom_bar(stat = "identity", show.legend = FALSE) +
    geom_errorbar(aes(ymin = mean_confidence - sem, ymax = mean_confidence + sem), width = 0.2) +
    scale_fill_manual(values = choice_colors) +
    labs(
      title = plot_title,
      subtitle = "Confidence scores from Part 2 (consistent trials only)",
      x = "Participant's Choice",
      y = "Mean Confidence"
    ) +
    scale_y_continuous(limits = y_limits, expand = c(0, 0)) +
    theme_minimal() +
    theme(plot.title = element_text(size = 12, face = "bold"))
}

# --- Generate and print each plot separately ---
plot_all <- build_conf_plot(plot_data_all, "All Participants")
plot_r   <- build_conf_plot(plot_data_r, "Participants Who Mentioned the Rule")
plot_nr  <- build_conf_plot(plot_data_nr, "Participants Who Did NOT Mention the Rule")

# print separately so they appear one under another
print(plot_all)
print(plot_r)
print(plot_nr)


```




### Hypothesis 10 (RT: CORRECT VERSUS INCORRECT (all trials))

```{r hypothesis_9, include = FALSE, cache=F}


rt_pooled_correct <-phase_2_df %>%
  ungroup() %>%  
  filter(!is_catch_trial, is_consistent) %>%
  summarise(pooled_median_rt = median(rt, na.rm = TRUE)) %>%
  pull(pooled_median_rt)

r_rt_pooled_correct<- phase_2_df %>%
  ungroup() %>%  
  filter(!is_catch_trial, is_consistent, mentioned_rule) %>%
  summarise(pooled_median_rt = median(rt, na.rm = TRUE)) %>%
  pull(pooled_median_rt)

nr_rt_pooled_correct <-phase_2_df %>%
  ungroup() %>%  
  filter(!is_catch_trial,!mentioned_rule, is_consistent) %>%
  summarise(pooled_median_rt = median(rt, na.rm = TRUE)) %>%
  pull(pooled_median_rt)

rt_pooled_incorrect <- phase_2_df %>%
  ungroup() %>%  
  filter(!is_catch_trial, !is_consistent) %>%
  summarise(pooled_median_rt = median(rt, na.rm = TRUE)) %>%
  pull(pooled_median_rt)

r_rt_pooled_incorrect <- phase_2_df %>%
  ungroup() %>%  
  filter(!is_catch_trial, mentioned_rule, !is_consistent) %>%
  summarise(pooled_median_rt = median(rt, na.rm = TRUE)) %>%
  pull(pooled_median_rt)

nr_rt_pooled_incorrect <- phase_2_df %>%
  ungroup() %>%  
  filter(!is_catch_trial, !mentioned_rule, !is_consistent) %>%
  summarise(pooled_median_rt = median(rt, na.rm = TRUE)) %>%
  pull(pooled_median_rt)

rt_correct <- phase_2_df %>%
  group_by(subj_id) %>%
  filter(!is_catch_trial, is_consistent) %>%
  summarise(median_rt = median(rt, na.rm=TRUE))

r_rt_correct <- phase_2_df %>%
  group_by(subj_id) %>%
  filter(!is_catch_trial, is_consistent, mentioned_rule) %>%
  summarise(median_rt = median(rt, na.rm=TRUE))

nr_rt_correct <- phase_2_df %>%
  group_by(subj_id) %>%
  filter(!is_catch_trial, is_consistent, !mentioned_rule) %>%
  summarise(median_rt = median(rt, na.rm=TRUE))

rt_incorrect <- phase_2_df %>%
  group_by(subj_id) %>%
  filter(!is_catch_trial, !is_consistent) %>%
  summarise(median_rt = median(rt, na.rm=TRUE))

r_rt_incorrect <- phase_2_df %>%
  group_by(subj_id) %>%
  filter(!is_catch_trial, !is_consistent, mentioned_rule) %>%
  summarise(median_rt = median(rt, na.rm=TRUE))

nr_rt_incorrect <- phase_2_df %>%
  group_by(subj_id) %>%
  filter(!is_catch_trial, !is_consistent, !mentioned_rule) %>%
  summarise(median_rt = median(rt, na.rm=TRUE))





```

In part 2, the median reaction time for consistent choices was `r rt_pooled_correct%>% printnum()`and for inconsistent choices was `r rt_pooled_incorrect%>%printnum()`. A paired t-test reveals that there is a significant difference between median reaction times (`r apa_print(wilcox.test(x =rt_correct$median_rt,y = rt_incorrect$median_rt,alternative = "two.sided",paired = TRUE))$statistic`). 

For participants who mentioned rule, the median reaction time for consistent choices was `r r_rt_pooled_correct%>% printnum()`and for inconsistent choices was `r r_rt_pooled_incorrect%>%printnum()`. A paired t-test reveals that there is a significant difference between median reaction times (`r apa_print(wilcox.test(x =r_rt_correct$median_rt,y = r_rt_incorrect$median_rt,alternative = "two.sided",paired = TRUE))$statistic`).

For participants who did not mention the rule, the median reaction time for consistent choices was `r nr_rt_pooled_correct%>% printnum()`and for inconsistent choices was `r nr_rt_pooled_incorrect%>%printnum()`. A paired t-test reveals that there is a significant difference between median reaction times (`r apa_print(wilcox.test(x =nr_rt_correct$median_rt,y = nr_rt_incorrect$median_rt,alternative = "two.sided",paired = TRUE))$statistic`).

### Hypothesis 11 (RT: GEMS VERSUS STONES (for correct trials))

```{r hypothesis_10, include = FALSE, cache=F}

rt_pooled_gems <- phase_2_df %>%
  ungroup() %>%  
  filter(!is_catch_trial, is_consistent, chose_gems) %>%
  summarise(pooled_median_rt = median(rt, na.rm = TRUE)) %>%
  pull(pooled_median_rt)

r_rt_pooled_gems <- phase_2_df %>%
  ungroup() %>%  
  filter(!is_catch_trial, is_consistent, chose_gems, mentioned_rule) %>%
  summarise(pooled_median_rt = median(rt, na.rm = TRUE)) %>%
  pull(pooled_median_rt)

nr_rt_pooled_gems <- phase_2_df %>%
  ungroup() %>%  
  filter(!is_catch_trial, !mentioned_rule, is_consistent, chose_gems) %>%
  summarise(pooled_median_rt = median(rt, na.rm = TRUE)) %>%
  pull(pooled_median_rt)

rt_pooled_nongems <- phase_2_df %>%
  ungroup() %>%  
  filter(!is_catch_trial, is_consistent, !chose_gems) %>%
  summarise(pooled_median_rt = median(rt, na.rm = TRUE)) %>%
  pull(pooled_median_rt)

r_rt_pooled_nongems <- phase_2_df %>%
  ungroup() %>%  
  filter(!is_catch_trial, mentioned_rule,  is_consistent, !chose_gems) %>%
  summarise(pooled_median_rt = median(rt, na.rm = TRUE)) %>%
  pull(pooled_median_rt)

nr_rt_pooled_nongems <- phase_2_df %>%
  ungroup() %>%  
  filter(!is_catch_trial, !mentioned_rule, is_consistent, !chose_gems) %>%
  summarise(pooled_median_rt = median(rt, na.rm = TRUE)) %>%
  pull(pooled_median_rt)

rt_gems <- phase_2_df %>%
  group_by(subj_id) %>%
  filter(!is_catch_trial, is_consistent, chose_gems) %>%
  summarise(median_rt = median(rt, na.rm=TRUE))

r_rt_gems <- phase_2_df %>%
  group_by(subj_id) %>%
  filter(!is_catch_trial, is_consistent, chose_gems, mentioned_rule) %>%
  summarise(median_rt = median(rt, na.rm=TRUE))

nr_rt_gems <- phase_2_df %>%
  group_by(subj_id) %>%
  filter(!is_catch_trial, is_consistent, chose_gems, !mentioned_rule) %>%
  summarise(median_rt = median(rt, na.rm=TRUE))

rt_nongems <- phase_2_df %>%
  group_by(subj_id) %>%
  filter(!is_catch_trial, is_consistent, !chose_gems) %>%
  summarise(median_rt = median(rt, na.rm=TRUE))

r_rt_nongems <- phase_2_df %>%
  group_by(subj_id) %>%
  filter(!is_catch_trial, is_consistent, !chose_gems, mentioned_rule) %>%
  summarise(median_rt = median(rt, na.rm=TRUE))


nr_rt_nongems <- phase_2_df %>%
  group_by(subj_id) %>%
  filter(!is_catch_trial, is_consistent, !chose_gems, !mentioned_rule) %>%
  summarise(median_rt = median(rt, na.rm=TRUE))

rt_gem_diff <- rt_gems %>%
  rename(median_rt_gems = median_rt) %>%
  inner_join(rt_nongems %>%
               rename(median_rt_nongems = median_rt),
             by = "subj_id")

r_rt_gem_diff <- r_rt_gems %>%
  rename(median_rt_gems = median_rt) %>%
  inner_join(r_rt_nongems %>%
               rename(median_rt_nongems = median_rt),
             by = "subj_id")

nr_rt_gem_diff <-nr_rt_gems %>%
  rename(median_rt_gems = median_rt) %>%
  inner_join(nr_rt_nongems %>%
               rename(median_rt_nongems = median_rt),
             by = "subj_id")





```

In part 2, the median reaction time when choosing gems in correct responses was `r rt_pooled_gems%>%printnum()`and for choosing stones was `r rt_pooled_nongems %>%printnum()`. A paired t-test reveals that there is significant difference between median reaction times (`r apa_print(wilcox.test(rt_gem_diff$median_rt_gems,rt_gem_diff$median_rt_nongems,paired = TRUE))$statistic`). 

For participants that mentioned the rule, the median reaction time when choosing gems in correct responses was `r r_rt_pooled_gems%>%printnum()`and for choosing stones was `r r_rt_pooled_nongems %>%printnum()`. A paired t-test reveals that there is significant difference between median reaction times (`r apa_print(wilcox.test(r_rt_gem_diff$median_rt_gems,r_rt_gem_diff$median_rt_nongems,paired = TRUE))$statistic`). 

For participants that did not mention the rule,  the median reaction time when choosing gems in correct responses was `r nr_rt_pooled_gems%>%printnum()`and for choosing stones was `r nr_rt_pooled_nongems %>%printnum()`. A paired t-test reveals that there is no significant difference between median reaction times (`r apa_print(wilcox.test(nr_rt_gem_diff$median_rt_gems,nr_rt_gem_diff$median_rt_nongems,paired = TRUE))$statistic`). 


### Hypothesis 12 (RT: STONES VERSUS STONES ONLY)

```{r hypothesis_12, include = FALSE, cache=F}

median_rt_other <- phase_2_df %>%
  ungroup() %>%  
  filter(!is_catch_trial, is_consistent,chose_other) %>%
  summarise(pooled_median_rt = median(rt, na.rm = TRUE)) %>%
  pull(pooled_median_rt)

r_median_rt_other <- phase_2_df %>%
  ungroup() %>%  
  filter(!is_catch_trial, mentioned_rule, is_consistent,chose_other) %>%
  summarise(pooled_median_rt = median(rt, na.rm = TRUE)) %>%
  pull(pooled_median_rt)

nr_median_rt_other <- phase_2_df %>%
  ungroup() %>%  
  filter(!is_catch_trial, !mentioned_rule, is_consistent,chose_other) %>%
  summarise(pooled_median_rt = median(rt, na.rm = TRUE)) %>%
  pull(pooled_median_rt)

median_rt_stones<- phase_2_df %>%
  ungroup() %>% 
  filter(!is_catch_trial, !is_consistent, chose_onlystones) %>%
  summarise(pooled_median_rt = median(rt, na.rm = TRUE)) %>%
  pull(pooled_median_rt)

r_median_rt_stones<- phase_2_df %>%
  ungroup() %>% 
  filter(!is_catch_trial, mentioned_rule, !is_consistent, chose_onlystones) %>%
  summarise(pooled_median_rt = median(rt, na.rm = TRUE)) %>%
  pull(pooled_median_rt)

nr_median_rt_stones<- phase_2_df %>%
  ungroup() %>% 
  filter(!is_catch_trial, !mentioned_rule, !is_consistent, chose_onlystones) %>%
  summarise(pooled_median_rt = median(rt, na.rm = TRUE)) %>%
  pull(pooled_median_rt)

rt_other <- phase_2_df %>%
  group_by(subj_id) %>%
  filter(!is_catch_trial, is_consistent,chose_other) %>%
  summarise(median_rt = median(rt, na.rm=TRUE))

r_rt_other <- phase_2_df %>%
  group_by(subj_id) %>%
  filter(!is_catch_trial, mentioned_rule, is_consistent,chose_other) %>%
  summarise(median_rt = median(rt, na.rm=TRUE))

nr_rt_other <- phase_2_df %>%
  group_by(subj_id) %>%
  filter(!is_catch_trial, is_consistent,chose_other, !mentioned_rule) %>%
  summarise(median_rt = median(rt, na.rm=TRUE))


rt_stones <- phase_2_df %>%
  group_by(subj_id) %>%
  filter(!is_catch_trial, is_consistent,chose_onlystones) %>%
  summarise(median_rt = median(rt, na.rm=TRUE))

r_rt_stones <- phase_2_df %>%
  group_by(subj_id) %>%
  filter(!is_catch_trial, is_consistent,chose_onlystones, mentioned_rule) %>%
  summarise(median_rt = median(rt, na.rm=TRUE))

nr_rt_stones <- phase_2_df %>%
  group_by(subj_id) %>%
  filter(!is_catch_trial, is_consistent,chose_onlystones, !mentioned_rule) %>%
  summarise(median_rt = median(rt, na.rm=TRUE))

rt_joined <- rt_gems %>%
  rename(median_rt_other = median_rt) %>%
  inner_join(rt_stones %>%
               rename(median_rt_stones = median_rt),
             by = "subj_id")

r_rt_joined <- r_rt_gems %>%
  rename(median_rt_other = median_rt) %>%
  inner_join(r_rt_stones %>%
               rename(median_rt_stones = median_rt),
             by = "subj_id")

nr_rt_joined <- nr_rt_gems %>%
  rename(median_rt_other = median_rt) %>%
  inner_join(nr_rt_stones %>%
               rename(median_rt_stones = median_rt),
             by = "subj_id")



```

In part 2, the median reaction time when choosing the other position in correct responses was `r median_rt_other%>%printnum()`and for only stones was `r median_rt_stones%>%printnum()`. A paired t-test reveals that there is no significant difference between median reaction times (`r apa_print(wilcox.test(rt_joined$median_rt_other, rt_joined$median_rt_stones, alternative = "two.sided", paired = TRUE))$statistic`). 

For participants who mentioned the rule, the median reaction time when choosing the other position in correct responses was `r r_median_rt_other%>%printnum()`and for only stones was `r r_median_rt_stones%>%printnum()`. A paired t-test reveals that there is no significant difference between median reaction times (`r apa_print(wilcox.test(r_rt_joined$median_rt_other, r_rt_joined$median_rt_stones, alternative = "two.sided", paired = TRUE))$statistic`). 

For participants who did not mention the rule, the median reaction time when choosing the other position in correct responses was `r nr_median_rt_other%>%printnum()`and for only stones was `r nr_median_rt_stones%>%printnum()`. A paired t-test reveals that there is no significant difference between median reaction times (`r apa_print(wilcox.test(nr_rt_joined$median_rt_other, nr_rt_joined$median_rt_stones, alternative = "two.sided", paired = TRUE))$statistic`). 



```{r rtgraph, cache=F, fig.width=8}

## plot of median rt in correct trials 
plot_data <- phase_2_df %>%
  filter(is_consistent, !is_catch_trial) %>%
  mutate(
    choice_type = case_when(
      chose_gems       ~ "Chose Gems",
      chose_other      ~ "Chose Other",
      chose_onlystones ~ "Chose Only Stones",
      TRUE             ~ NA_character_ 
    )
  ) %>%
  filter(!is.na(choice_type)) %>%
  group_by(choice_type) %>%
  summarise(
    median_rt = median(rt, na.rm = TRUE),
    n = n(),
    sem = sd(rt, na.rm = TRUE) / sqrt(n),
    .groups = 'drop'
  )

rt_plot <- ggplot(plot_data, aes(x = choice_type, y = median_rt, fill = choice_type)) +
  geom_bar(stat = "identity", show.legend = FALSE) +
  geom_errorbar(
    aes(ymin = median_rt - sem, ymax = median_rt + sem),
    width = 0.2
  ) +
  labs(
    title = "Median RT by Choice",
    x = "Participant's Choice",
    y = "Median rt"
  ) +
  theme_minimal()

print(rt_plot)

```


## Exploratory analysis 

### Hypothesis 8.5 (CONFIDENCE: STONES VERSUS STONES ONLY)
```{r hypothesis_8.5, include = FALSE, cache=F}
otherstone_conf <- phase_2_df %>% 
  group_by(subj_id) %>%
  filter(!is_catch_trial, is_consistent, chose_other) %>%
  summarise(mean_conf=mean(confidence),
            median = median(confidence))

r_otherstone_conf <- phase_2_df %>% 
  group_by(subj_id) %>%
  filter(!is_catch_trial, is_consistent, chose_other, mentioned_rule) %>%
  summarise(mean_conf=mean(confidence),
            median = median(confidence))

nr_otherstone_conf <- phase_2_df %>% 
  group_by(subj_id) %>%
  filter(!is_catch_trial, is_consistent, chose_other, !mentioned_rule) %>%
  summarise(mean_conf=mean(confidence),
            median = median(confidence))


onlystone_conf <- phase_2_df %>% 
  group_by(subj_id) %>%
  filter(!is_catch_trial, is_consistent, chose_onlystones) %>%
  summarise(mean_conf=mean(confidence),
            median = median(confidence))

r_onlystone_conf <- phase_2_df %>% 
  group_by(subj_id) %>%
  filter(!is_catch_trial, is_consistent, chose_onlystones, mentioned_rule) %>%
  summarise(mean_conf=mean(confidence),
            median = median(confidence))

nr_onlystone_conf <- phase_2_df %>% 
  group_by(subj_id) %>%
  filter(!is_catch_trial, is_consistent, chose_onlystones, !mentioned_rule) %>%
  summarise(mean_conf=mean(confidence),
            median = median(confidence))

conf_df <- otherstone_conf %>%
  rename(mean_conf_other = mean_conf, median_other = median) %>%
  inner_join(
    onlystone_conf %>%
      rename(mean_conf_onlystone = mean_conf, median_onlystone = median),
    by = "subj_id"
  )

r_conf_df <- r_otherstone_conf %>%
  rename(mean_conf_other = mean_conf, median_other = median) %>%
  inner_join(
    r_onlystone_conf %>%
      rename(mean_conf_onlystone = mean_conf, median_onlystone = median),
    by = "subj_id"
  )

nr_conf_df <- nr_otherstone_conf %>%
  rename(mean_conf_other = mean_conf, median_other = median) %>%
  inner_join(
    nr_onlystone_conf %>%
      rename(mean_conf_onlystone = mean_conf, median_onlystone = median),
    by = "subj_id"
  )


```

In part 2, mean confidence when touching the stones only position on trials in which participants were correct was `r onlystone_conf$mean_conf %>%mean()%>%printnum()` (median=`r onlystone_conf$median%>%median()%>%printnum() `). In trials which they chose other stone position, it was `r otherstone_conf$mean_conf %>%mean()%>%printnum()` (median=`r  otherstone_conf$median%>%median()%>%printnum() `). This difference was not significant (`r apa_print(t.test(conf_df$mean_conf_other, conf_df$mean_conf_onlystone, paired = TRUE))$statistic`).

For participants who mentioned the rule, mean confidence when touching the stones only position on trials in which participants were correct was `r r_onlystone_conf$mean_conf %>%mean()%>%printnum()` (median=`r r_onlystone_conf$median%>%median()%>%printnum() `). In trials which they chose other stone position, it was `r r_otherstone_conf$mean_conf %>%mean()%>%printnum()` (median=`r  r_otherstone_conf$median%>%median()%>%printnum() `). This difference was not significant (`r apa_print(t.test(r_conf_df$mean_conf_other, r_conf_df$mean_conf_onlystone, paired = TRUE))$statistic`).

For participants who did not mention the rule, mean confidence when touching the stones only position on trials in which participants were correct was `r nr_onlystone_conf$mean_conf %>%mean()%>%printnum()` (median=`r nr_onlystone_conf$median%>%median()%>%printnum() `). In trials which they chose other stone position, it was `r nr_otherstone_conf$mean_conf %>%mean()%>%printnum()` (median=`r  nr_otherstone_conf$median%>%median()%>%printnum() `). This difference was not significant (`r apa_print(t.test(nr_conf_df$mean_conf_other, nr_conf_df$mean_conf_onlystone, paired = TRUE))$statistic`).

### estimates of own performance


```{r correlation, include = FALSE, cache=F}
## Correlation between estimate and actual performance 
# part 1

total_chose_gems_part1 <- phase_1_df %>%
  group_by(subj_id) %>%
  filter(!is_catch_trial) %>% 
  summarise(total_gems = sum(chose_gems, na.rm = TRUE)) 

estimate_chose_gems_part1 <- phase_1_df %>% 
  group_by(subj_id) %>%
  summarise(mean_estimate = mean(number_correct_part1, na.rm = TRUE))

correlation_data <- inner_join(total_chose_gems_part1, 
                               estimate_chose_gems_part1, 
                               by = "subj_id")

cor_part1 <- cor.test(x = correlation_data$total_gems, 
         y = correlation_data$mean_estimate, 
         method = "pearson")

# part 2

total_chose_gems_part2 <- phase_2_df %>%
  group_by(subj_id) %>%
  filter(!is_catch_trial) %>% 
  summarise(consistent = sum(is_consistent, na.rm = TRUE)) 

estimate_chose_gems_part2 <- phase_2_df %>% 
  group_by(subj_id) %>%
  summarise(mean_estimate = mean(number_correct_part2, na.rm = TRUE))

correlation_data <- inner_join(total_chose_gems_part2, 
                               estimate_chose_gems_part2, 
                               by = "subj_id")

cor_part2 <- cor.test(x = correlation_data$consistent, 
         y = correlation_data$mean_estimate, 
         method = "pearson")


```


People can estimate performance in part 1; Pearson correlation `r sprintf("r = %.2f, 95%% CI [%.2f, %.2f]", cor_part1$estimate, cor_part1$conf.int[1], cor_part1$conf.int[2])` p `printp(cor_part1$p.value)`. In Part 2, they are also able to estimate their performance in part 2; Pearson correlation `r sprintf("r = %.2f, 95%% CI [%.2f, %.2f]", cor_part2$estimate,cor_part2$conf.int[1], cor_part2$conf.int[2])` p `printp(cor_part2$p.value)`. 




```{r estimate,  cache=F, fig.width=8}

library(ggplot2)
library(patchwork)
total_chose_gems_part1 <- phase_1_df %>%
  group_by(subj_id) %>%
  filter(!is_catch_trial) %>%
  summarise(total_gems = sum(chose_gems, na.rm = TRUE))

estimate_chose_gems_part1 <- phase_1_df %>%
  group_by(subj_id) %>%
  summarise(mean_estimate = mean(number_correct_part1, na.rm = TRUE))

correlation_data_part1 <- inner_join(total_chose_gems_part1,
                                     estimate_chose_gems_part1,
                                     by = "subj_id")

plot_part1 <- ggplot(correlation_data_part1, aes(x = total_gems, y = mean_estimate)) +
  geom_point(alpha = 0.7) + # Add points
  geom_smooth(method = "lm", col = "blue", se = FALSE) + 
  labs(
    title = "Part 1: Total Gems vs. Mean Estimate",
    x = "Total Gems Chosen",
    y = "Mean Estimate (Part 1)"
  ) +
  theme_minimal() + 
  coord_cartesian(xlim = c(0, 50), ylim = c(0, 50))

total_chose_gems_part2 <- phase_2_df %>%
  group_by(subj_id) %>%
  filter(!is_catch_trial) %>%
  summarise(consistent = sum(is_consistent, na.rm = TRUE))

estimate_chose_gems_part2 <- phase_2_df %>%
  group_by(subj_id) %>%
  summarise(mean_estimate = mean(number_correct_part2, na.rm = TRUE))

correlation_data_part2 <- inner_join(total_chose_gems_part2,
                                     estimate_chose_gems_part2,
                                     by = "subj_id")

plot_part2 <- ggplot(correlation_data_part2, aes(x = consistent, y = mean_estimate)) +
  geom_point(alpha = 0.7) + 
  geom_smooth(method = "lm", col = "red", se = FALSE) + # Add linear regression line
  labs(
    title = "Part 2: Consistency vs. Mean Estimate",
    x = "Total Consistent Choices",
    y = "Mean Estimate (Part 2)"
  ) +
  theme_minimal() + 
  coord_cartesian(xlim = c(0, 50), ylim = c(0, 50))

combined_plot <- plot_part1 + plot_part2

print(combined_plot)
```


### Effect of numbers on choice

```{r higherorlower, include = FALSE, cache=F}

higher_df <- phase_2_df %>%
  group_by(subj_id) %>%
  filter(!is_catch_trial, !is_consistent) %>%
  mutate(
    higher = case_when(
      response_position == "middle" & correct_choice_position == "left"  ~ middle_number > right_number,
      response_position == "middle" & correct_choice_position == "right" ~ middle_number > left_number,
      
      response_position == "right" & correct_choice_position == "left"   ~ right_number > middle_number,
      response_position == "right" & correct_choice_position == "middle" ~ right_number > left_number,
      
      response_position == "left" & correct_choice_position == "middle" ~ left_number > right_number,
      response_position == "left" & correct_choice_position == "right"  ~ left_number > middle_number,
      
      # Default case (e.g., if a condition wasn't met, or if you had a TRUE ~ FALSE)
      # This will result in NA if no condition is met, which is fine.
      TRUE ~ NA
    )
  ) %>%
  # --- ADDED FILTER STEP ---
  # This filters the dataframe to *only* include rows where the
  # two relevant non-correct numbers were NOT equal.
  filter(
    case_when(
      response_position == "middle" & correct_choice_position == "left"  ~ middle_number != right_number,
      response_position == "middle" & correct_choice_position == "right" ~ middle_number != left_number,
      
      response_position == "right" & correct_choice_position == "left"   ~ right_number != middle_number,
      response_position == "right" & correct_choice_position == "middle" ~ right_number != left_number,
      
      response_position == "left" & correct_choice_position == "middle" ~ left_number != right_number,
      response_position == "left" & correct_choice_position == "right"  ~ left_number != middle_number,
      
      # This default drops any rows that didn't match the logic above
      # (e.g., rows that resulted in NA for 'higher').
      TRUE ~ FALSE
    )
  )



participant_summary <- higher_df %>%
  group_by(subj_id) %>%
  summarise(
    prop_higher = mean(higher, na.rm = TRUE)
  )


```

When participants were inaccurate in part 2, the mean probability for the participant to choose the option with a greater number was `r higher_df %>% ungroup() %>% summarise(mean=mean(higher)) %>% pull(mean) %>% printnum()`. This was significantly less than chance (`r apa_print(t.test(participant_summary$prop_higher,mu = 0.5,alternative = "two.sided"))$statistic`). 

# Results

# Discussion


\newpage

# References

::: {#refs custom-style="Bibliography"}
:::
